{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a68a04",
   "metadata": {},
   "source": [
    "# Telus Visualization Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37758c1f",
   "metadata": {},
   "source": [
    "In this notebook I explain the data cleaning process that I performed prior to analyzing the data. \n",
    "\n",
    "In the first few sections I will read and explore the dataset. My exploration step will reveal that there are several missing data points, in almost every field. These missing data (such as city, state, date_time, and latitude and londitude) need to be identified from the other fields or from a complimentary dataset. An example is identification of state for non-USA cities from the field city using an aditional dataset. My exploration also shows that a text field (duration) needs to be transformed into numeric values. Two new fields (country, and population) need to be added to the dataset. And finaly some format conversion, and dropping of useless fiels will be required.\n",
    "\n",
    "In the following sections I will provide the codes that I used to perform the required actions mentioned above. Most of these sections are supplemented by few queries to check the results and confirm the correctness of the generated data.\n",
    "\n",
    "At the end the transformed and summerized table will be saved to be uploaded on a Google Cloud database, and Tableau for visualization and insight extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7209ebc7",
   "metadata": {},
   "source": [
    "## Reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf58049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required packages\n",
    "\n",
    "import pandas as pd\n",
    "import pandasql as pdql\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import pycountry\n",
    "import durations\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f627a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>date_time</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration</th>\n",
       "      <th>stats</th>\n",
       "      <th>report_link</th>\n",
       "      <th>text</th>\n",
       "      <th>posted</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife was driving southeast on a fairly popu...</td>\n",
       "      <td>Chester</td>\n",
       "      <td>VA</td>\n",
       "      <td>2019-12-12T18:43:00</td>\n",
       "      <td>light</td>\n",
       "      <td>5 seconds</td>\n",
       "      <td>Occurred : 12/12/2019 18:43  (Entered as : 12/...</td>\n",
       "      <td>http://www.nuforc.org/webreports/151/S151739.html</td>\n",
       "      <td>My wife was driving southeast on a fairly popu...</td>\n",
       "      <td>2019-12-22T00:00:00</td>\n",
       "      <td>37.343152</td>\n",
       "      <td>-77.408582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I think that I may caught a UFO on the NBC Nig...</td>\n",
       "      <td>Rocky Hill</td>\n",
       "      <td>CT</td>\n",
       "      <td>2019-03-22T18:30:00</td>\n",
       "      <td>circle</td>\n",
       "      <td>3-5 seconds</td>\n",
       "      <td>Occurred : 3/22/2019 18:30  (Entered as : 03/2...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145297.html</td>\n",
       "      <td>I think that I may caught a UFO on the NBC Nig...</td>\n",
       "      <td>2019-03-29T00:00:00</td>\n",
       "      <td>41.664800</td>\n",
       "      <td>-72.639300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I woke up late in the afternoon 3:30-4pm. I we...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Occurred : 4/1/2019 15:45  (Entered as : April...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145556.html</td>\n",
       "      <td>I woke up late in the afternoon 3:30-4pm.  I w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was driving towards the intersection of fall...</td>\n",
       "      <td>Ottawa</td>\n",
       "      <td>ON</td>\n",
       "      <td>2019-04-17T02:00:00</td>\n",
       "      <td>teardrop</td>\n",
       "      <td>10 seconds</td>\n",
       "      <td>Occurred : 4/17/2019 02:00  (Entered as : 04-1...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145697.html</td>\n",
       "      <td>I was driving towards the intersection of fall...</td>\n",
       "      <td>2019-04-18T00:00:00</td>\n",
       "      <td>45.381383</td>\n",
       "      <td>-75.708501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In Peoria Arizona, I saw a cigar shaped craft ...</td>\n",
       "      <td>Peoria</td>\n",
       "      <td>NY</td>\n",
       "      <td>2009-03-15T18:00:00</td>\n",
       "      <td>cigar</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>Occurred : 3/15/2009 18:00  (Entered as : 03/1...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145723.html</td>\n",
       "      <td>In Peoria, Arizona, I saw a cigar shaped craft...</td>\n",
       "      <td>2019-04-18T00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary        city state  \\\n",
       "0  My wife was driving southeast on a fairly popu...     Chester    VA   \n",
       "1  I think that I may caught a UFO on the NBC Nig...  Rocky Hill    CT   \n",
       "2  I woke up late in the afternoon 3:30-4pm. I we...         NaN   NaN   \n",
       "3  I was driving towards the intersection of fall...      Ottawa    ON   \n",
       "4  In Peoria Arizona, I saw a cigar shaped craft ...      Peoria    NY   \n",
       "\n",
       "             date_time     shape     duration  \\\n",
       "0  2019-12-12T18:43:00     light    5 seconds   \n",
       "1  2019-03-22T18:30:00    circle  3-5 seconds   \n",
       "2                  NaN       NaN          NaN   \n",
       "3  2019-04-17T02:00:00  teardrop   10 seconds   \n",
       "4  2009-03-15T18:00:00     cigar    2 minutes   \n",
       "\n",
       "                                               stats  \\\n",
       "0  Occurred : 12/12/2019 18:43  (Entered as : 12/...   \n",
       "1  Occurred : 3/22/2019 18:30  (Entered as : 03/2...   \n",
       "2  Occurred : 4/1/2019 15:45  (Entered as : April...   \n",
       "3  Occurred : 4/17/2019 02:00  (Entered as : 04-1...   \n",
       "4  Occurred : 3/15/2009 18:00  (Entered as : 03/1...   \n",
       "\n",
       "                                         report_link  \\\n",
       "0  http://www.nuforc.org/webreports/151/S151739.html   \n",
       "1  http://www.nuforc.org/webreports/145/S145297.html   \n",
       "2  http://www.nuforc.org/webreports/145/S145556.html   \n",
       "3  http://www.nuforc.org/webreports/145/S145697.html   \n",
       "4  http://www.nuforc.org/webreports/145/S145723.html   \n",
       "\n",
       "                                                text               posted  \\\n",
       "0  My wife was driving southeast on a fairly popu...  2019-12-22T00:00:00   \n",
       "1  I think that I may caught a UFO on the NBC Nig...  2019-03-29T00:00:00   \n",
       "2  I woke up late in the afternoon 3:30-4pm.  I w...                  NaN   \n",
       "3  I was driving towards the intersection of fall...  2019-04-18T00:00:00   \n",
       "4  In Peoria, Arizona, I saw a cigar shaped craft...  2019-04-18T00:00:00   \n",
       "\n",
       "   city_latitude  city_longitude  \n",
       "0      37.343152      -77.408582  \n",
       "1      41.664800      -72.639300  \n",
       "2            NaN             NaN  \n",
       "3      45.381383      -75.708501  \n",
       "4            NaN             NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data set into a dataframe and display the first 5 rows\n",
    "df_ufo=pd.read_csv('file name')\n",
    "df_ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd3d61ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_ascii</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>country</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>capital</th>\n",
       "      <th>population</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>35.6897</td>\n",
       "      <td>139.6922</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>JPN</td>\n",
       "      <td>Tōkyō</td>\n",
       "      <td>primary</td>\n",
       "      <td>37977000.0</td>\n",
       "      <td>1392685764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jakarta</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>-6.2146</td>\n",
       "      <td>106.8451</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>ID</td>\n",
       "      <td>IDN</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>primary</td>\n",
       "      <td>34540000.0</td>\n",
       "      <td>1360771077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>28.6600</td>\n",
       "      <td>77.2300</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>admin</td>\n",
       "      <td>29617000.0</td>\n",
       "      <td>1356872604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>18.9667</td>\n",
       "      <td>72.8333</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>Mahārāshtra</td>\n",
       "      <td>admin</td>\n",
       "      <td>23355000.0</td>\n",
       "      <td>1356226629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manila</td>\n",
       "      <td>Manila</td>\n",
       "      <td>14.5958</td>\n",
       "      <td>120.9772</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>PH</td>\n",
       "      <td>PHL</td>\n",
       "      <td>Manila</td>\n",
       "      <td>primary</td>\n",
       "      <td>23088000.0</td>\n",
       "      <td>1608618140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city city_ascii      lat       lng      country iso2 iso3   admin_name  \\\n",
       "0    Tokyo      Tokyo  35.6897  139.6922        Japan   JP  JPN        Tōkyō   \n",
       "1  Jakarta    Jakarta  -6.2146  106.8451    Indonesia   ID  IDN      Jakarta   \n",
       "2    Delhi      Delhi  28.6600   77.2300        India   IN  IND        Delhi   \n",
       "3   Mumbai     Mumbai  18.9667   72.8333        India   IN  IND  Mahārāshtra   \n",
       "4   Manila     Manila  14.5958  120.9772  Philippines   PH  PHL       Manila   \n",
       "\n",
       "   capital  population          id  \n",
       "0  primary  37977000.0  1392685764  \n",
       "1  primary  34540000.0  1360771077  \n",
       "2    admin  29617000.0  1356872604  \n",
       "3    admin  23355000.0  1356226629  \n",
       "4  primary  23088000.0  1608618140  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data set containing detailed geographical information into a dataframe and display the first 5 rows \n",
    "df_worldcities=pd.read_csv('file name')\n",
    "df_worldcities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24beb546",
   "metadata": {},
   "source": [
    "## Query Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df9f0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysql = lambda q: pdql.sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c621f5",
   "metadata": {},
   "source": [
    "## Exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a346b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "summary            object\n",
       "city               object\n",
       "state              object\n",
       "date_time          object\n",
       "shape              object\n",
       "duration           object\n",
       "stats              object\n",
       "report_link        object\n",
       "text               object\n",
       "posted             object\n",
       "city_latitude     float64\n",
       "city_longitude    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ufo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b7972d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88125, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ufo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "976b5f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "summary              30\n",
       "city                234\n",
       "state              5235\n",
       "date_time          1187\n",
       "shape              2498\n",
       "duration           3171\n",
       "stats                37\n",
       "report_link           0\n",
       "text                 55\n",
       "posted             1187\n",
       "city_latitude     16112\n",
       "city_longitude    16112\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of missing records in each field:\n",
    "df_ufo.shape[0]-df_ufo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da74018a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "summary            0.034043\n",
       "city               0.265532\n",
       "state              5.940426\n",
       "date_time          1.346950\n",
       "shape              2.834610\n",
       "duration           3.598298\n",
       "stats              0.041986\n",
       "report_link        0.000000\n",
       "text               0.062411\n",
       "posted             1.346950\n",
       "city_latitude     18.283121\n",
       "city_longitude    18.283121\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Percent of missing records in each fieald:\n",
    "100-(df_ufo.count()/df_ufo.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b5290ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>date_time</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration</th>\n",
       "      <th>stats</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife was driving southeast on a fairly popu...</td>\n",
       "      <td>Chester</td>\n",
       "      <td>VA</td>\n",
       "      <td>2019-12-12T18:43:00</td>\n",
       "      <td>light</td>\n",
       "      <td>5 seconds</td>\n",
       "      <td>Occurred : 12/12/2019 18:43  (Entered as : 12/...</td>\n",
       "      <td>37.343152</td>\n",
       "      <td>-77.408582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I think that I may caught a UFO on the NBC Nig...</td>\n",
       "      <td>Rocky Hill</td>\n",
       "      <td>CT</td>\n",
       "      <td>2019-03-22T18:30:00</td>\n",
       "      <td>circle</td>\n",
       "      <td>3-5 seconds</td>\n",
       "      <td>Occurred : 3/22/2019 18:30  (Entered as : 03/2...</td>\n",
       "      <td>41.664800</td>\n",
       "      <td>-72.639300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I woke up late in the afternoon 3:30-4pm. I we...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Occurred : 4/1/2019 15:45  (Entered as : April...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was driving towards the intersection of fall...</td>\n",
       "      <td>Ottawa</td>\n",
       "      <td>ON</td>\n",
       "      <td>2019-04-17T02:00:00</td>\n",
       "      <td>teardrop</td>\n",
       "      <td>10 seconds</td>\n",
       "      <td>Occurred : 4/17/2019 02:00  (Entered as : 04-1...</td>\n",
       "      <td>45.381383</td>\n",
       "      <td>-75.708501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In Peoria Arizona, I saw a cigar shaped craft ...</td>\n",
       "      <td>Peoria</td>\n",
       "      <td>NY</td>\n",
       "      <td>2009-03-15T18:00:00</td>\n",
       "      <td>cigar</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>Occurred : 3/15/2009 18:00  (Entered as : 03/1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88120</th>\n",
       "      <td>4 lights in formation over Tempe appear while ...</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2019-10-02T20:00:00</td>\n",
       "      <td>formation</td>\n",
       "      <td>3 minutes</td>\n",
       "      <td>Occurred : 10/2/2019 20:00  (Entered as : 10/2...</td>\n",
       "      <td>33.414036</td>\n",
       "      <td>-111.920920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88121</th>\n",
       "      <td>2 bright star like lights in the NNW skys,  ((...</td>\n",
       "      <td>Bolivar</td>\n",
       "      <td>MO</td>\n",
       "      <td>2019-10-02T20:00:00</td>\n",
       "      <td>light</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Occurred : 10/2/2019 20:00  (Entered as : 10/0...</td>\n",
       "      <td>37.642200</td>\n",
       "      <td>-93.399600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88122</th>\n",
       "      <td>I just witnessed a ‘Phoenix Lights’ type of fo...</td>\n",
       "      <td>North Port</td>\n",
       "      <td>FL</td>\n",
       "      <td>2019-10-02T20:03:00</td>\n",
       "      <td>formation</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Occurred : 10/2/2019 20:03  (Entered as : 10/0...</td>\n",
       "      <td>27.076210</td>\n",
       "      <td>-82.223280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88123</th>\n",
       "      <td>Witnessed an orange, slow moving light. Was lo...</td>\n",
       "      <td>Black Mountain</td>\n",
       "      <td>NC</td>\n",
       "      <td>2019-10-02T22:00:00</td>\n",
       "      <td>fireball</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>Occurred : 10/2/2019 22:00  (Entered as : 10/0...</td>\n",
       "      <td>35.605000</td>\n",
       "      <td>-82.313200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88124</th>\n",
       "      <td>Glowing lights in formation  just south of San...</td>\n",
       "      <td>Marin County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2019-10-02T22:00:00</td>\n",
       "      <td>sphere</td>\n",
       "      <td>3 minutes</td>\n",
       "      <td>Occurred : 10/2/2019 22:00  (Entered as : 10-0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88125 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 summary            city  \\\n",
       "0      My wife was driving southeast on a fairly popu...         Chester   \n",
       "1      I think that I may caught a UFO on the NBC Nig...      Rocky Hill   \n",
       "2      I woke up late in the afternoon 3:30-4pm. I we...             NaN   \n",
       "3      I was driving towards the intersection of fall...          Ottawa   \n",
       "4      In Peoria Arizona, I saw a cigar shaped craft ...          Peoria   \n",
       "...                                                  ...             ...   \n",
       "88120  4 lights in formation over Tempe appear while ...           Tempe   \n",
       "88121  2 bright star like lights in the NNW skys,  ((...         Bolivar   \n",
       "88122  I just witnessed a ‘Phoenix Lights’ type of fo...      North Port   \n",
       "88123  Witnessed an orange, slow moving light. Was lo...  Black Mountain   \n",
       "88124  Glowing lights in formation  just south of San...    Marin County   \n",
       "\n",
       "      state            date_time      shape     duration  \\\n",
       "0        VA  2019-12-12T18:43:00      light    5 seconds   \n",
       "1        CT  2019-03-22T18:30:00     circle  3-5 seconds   \n",
       "2       NaN                  NaN        NaN          NaN   \n",
       "3        ON  2019-04-17T02:00:00   teardrop   10 seconds   \n",
       "4        NY  2009-03-15T18:00:00      cigar    2 minutes   \n",
       "...     ...                  ...        ...          ...   \n",
       "88120    AZ  2019-10-02T20:00:00  formation    3 minutes   \n",
       "88121    MO  2019-10-02T20:00:00      light   20 seconds   \n",
       "88122    FL  2019-10-02T20:03:00  formation   20 seconds   \n",
       "88123    NC  2019-10-02T22:00:00   fireball    2 minutes   \n",
       "88124    CA  2019-10-02T22:00:00     sphere    3 minutes   \n",
       "\n",
       "                                                   stats  city_latitude  \\\n",
       "0      Occurred : 12/12/2019 18:43  (Entered as : 12/...      37.343152   \n",
       "1      Occurred : 3/22/2019 18:30  (Entered as : 03/2...      41.664800   \n",
       "2      Occurred : 4/1/2019 15:45  (Entered as : April...            NaN   \n",
       "3      Occurred : 4/17/2019 02:00  (Entered as : 04-1...      45.381383   \n",
       "4      Occurred : 3/15/2009 18:00  (Entered as : 03/1...            NaN   \n",
       "...                                                  ...            ...   \n",
       "88120  Occurred : 10/2/2019 20:00  (Entered as : 10/2...      33.414036   \n",
       "88121  Occurred : 10/2/2019 20:00  (Entered as : 10/0...      37.642200   \n",
       "88122  Occurred : 10/2/2019 20:03  (Entered as : 10/0...      27.076210   \n",
       "88123  Occurred : 10/2/2019 22:00  (Entered as : 10/0...      35.605000   \n",
       "88124  Occurred : 10/2/2019 22:00  (Entered as : 10-0...            NaN   \n",
       "\n",
       "       city_longitude  \n",
       "0          -77.408582  \n",
       "1          -72.639300  \n",
       "2                 NaN  \n",
       "3          -75.708501  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "88120     -111.920920  \n",
       "88121      -93.399600  \n",
       "88122      -82.223280  \n",
       "88123      -82.313200  \n",
       "88124             NaN  \n",
       "\n",
       "[88125 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ufo.drop([ 'report_link','posted','text'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26358d68",
   "metadata": {},
   "source": [
    "* Finding: \n",
    "\n",
    "The largest missing percentage belongs to the coordinates, followed by the state. \n",
    "\n",
    "Although it is unlikely, let's check whether there is any none-empty latitude/longitude record corresponding to a state with null value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5249ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(report_link)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(report_link)\n",
       "0                   0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking wether there are any not-empty latitude/longitude records corresponding to the states with null values\n",
    "query='select count(report_link) from df_ufo where state IS NULL AND city_latitude IS NOT NULL  '\n",
    "pysql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74cb56bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stats</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Occurred : 6/6/2019 19:00  (Entered as : 6/6/2...</td>\n",
       "      <td>Caloocan City (Philippines)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Occurred : 2/6/2006 04:30  (Entered as : 6/2/2...</td>\n",
       "      <td>Woodford Green (UK/England)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Occurred : 12/11/1762 21:00  (Entered as : 12/...</td>\n",
       "      <td>Lulworth, Dorsetshire (near) (UK/England)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Occurred : 7/10/1968 20:30  (Entered as : 07/1...</td>\n",
       "      <td>Tehran (Iran)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Occurred : 5/7/1972 00:00  (Entered as : 5/7/7...</td>\n",
       "      <td>Essex (UK/England)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>Occurred : 11/28/2019 05:50  (Entered as : 28/...</td>\n",
       "      <td>Pontypridd (UK/Wales)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4638</th>\n",
       "      <td>Occurred : 9/27/2019 20:00  (Entered as : 09/2...</td>\n",
       "      <td>Drakenstein, Paarl East (South Africa)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>Occurred : 9/29/2019 16:50  (Entered as : 09/2...</td>\n",
       "      <td>Santo André</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>Occurred : 9/29/2019 19:35  (Entered as : 09/2...</td>\n",
       "      <td>Tijuana (Mexico)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>Occurred : 9/30/2019 01:00  (Entered as : 09/3...</td>\n",
       "      <td>kerman , Iran</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4642 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  stats  \\\n",
       "0     Occurred : 6/6/2019 19:00  (Entered as : 6/6/2...   \n",
       "1     Occurred : 2/6/2006 04:30  (Entered as : 6/2/2...   \n",
       "2     Occurred : 12/11/1762 21:00  (Entered as : 12/...   \n",
       "3     Occurred : 7/10/1968 20:30  (Entered as : 07/1...   \n",
       "4     Occurred : 5/7/1972 00:00  (Entered as : 5/7/7...   \n",
       "...                                                 ...   \n",
       "4637  Occurred : 11/28/2019 05:50  (Entered as : 28/...   \n",
       "4638  Occurred : 9/27/2019 20:00  (Entered as : 09/2...   \n",
       "4639  Occurred : 9/29/2019 16:50  (Entered as : 09/2...   \n",
       "4640  Occurred : 9/29/2019 19:35  (Entered as : 09/2...   \n",
       "4641  Occurred : 9/30/2019 01:00  (Entered as : 09/3...   \n",
       "\n",
       "                                           city  \n",
       "0                   Caloocan City (Philippines)  \n",
       "1                   Woodford Green (UK/England)  \n",
       "2     Lulworth, Dorsetshire (near) (UK/England)  \n",
       "3                                 Tehran (Iran)  \n",
       "4                            Essex (UK/England)  \n",
       "...                                         ...  \n",
       "4637                      Pontypridd (UK/Wales)  \n",
       "4638     Drakenstein, Paarl East (South Africa)  \n",
       "4639                                Santo André  \n",
       "4640                           Tijuana (Mexico)  \n",
       "4641                              kerman , Iran  \n",
       "\n",
       "[4642 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if missing state information is included in the other fields\n",
    "query='select stats, city from df_ufo where city REGEXP \"[^a-z A-Z]\" AND state IS NULL'\n",
    "pysql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514f4da",
   "metadata": {},
   "source": [
    "* Finding: \n",
    "\n",
    "As expected, the missing states can not be identified from the coordinates (as those are missing too). By investigation, I noticed that some of the missing states are included in city and/or stats field.\n",
    "<br>\n",
    "\n",
    "In fact, out of the 5235 NULL entries for states, 4642 of them correspond to some mixed information in the field city. These records are mostly related to non-USA countries (4559 records).\n",
    "<br>\n",
    "\n",
    "If we extract those information, up to %89 (4642/5235*100) of missing states can be identified. Having the city, state, and country, we might be able to identify up to %16 of the %18  missing coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b60fc3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [state]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check wether there is any messy entries in state too:\n",
    "query='select state from df_ufo where state REGEXP \"[^a-z A-Z]\" '\n",
    "pysql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "809782f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LENGTH(state)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [LENGTH(state)]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check wether there is any entries in state with a different format:\n",
    "query='select  LENGTH(state)  from df_ufo where LENGTH(state)>2;'\n",
    "pysql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9fadf",
   "metadata": {},
   "source": [
    "* Finding: The state entries seem OK.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3dc7c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Checking the entries for a sample record with NULL value in city, state, date_time, shape, duration, latitude, and longitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "561c2598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurred : 4/1/2019 15:45  (Entered as : April01.19) Reported: 4/8/2019 9:42:31 PM 21:42 Posted: 4/12/2019 Location: Winnipeg (Canada),  Shape:  Duration:\n"
     ]
    }
   ],
   "source": [
    "print(df_ufo.stats[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42902faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I woke up late in the afternoon 3:30-4pm. I went to have a bath, while shaving my legs i noticed indentations around my left ankel. I t\n"
     ]
    }
   ],
   "source": [
    "print(df_ufo.summary[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e61148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I woke up late in the afternoon 3:30-4pm.  I went to have a bath, while shaving my legs i noticed indentations around my left ankel.  I then noticed that they went all the way around the backs of both my legs and up to my thighs.  It scared me because a few nights before I was telling my fiancee that was pretty sure that i was abducted before, he laughed then that was that.  I showed him the indentations and he was shocked.  He suffers from insomnia.  We woke up at the same time.  He only sleeps maybe 4-5 hrs a wk.  He said that he slept all night with me.  The indentations look like my legs were seperated into stirups, or like how a massage chair would hold your legs.  The indents were in rows of 1-1.5 lines from my ankles all the way up to my thighs just below my buttocks.  They were perfectly lined.  They disappeared within 2 hrs of waking up.  I couldnt talk a picture because i had just lost my cell phone.\n"
     ]
    }
   ],
   "source": [
    "print(df_ufo.text[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70cb515",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "### Based on my investigations and the project instruction, these are the data cleaning actions required prior to data analysis:\n",
    "<br>\n",
    "\n",
    "*   1- The missing/messy entries of city, state and country (which is a new field to be added) must be extracted from stats where possible. Care must be taken wherever there are cities with the same name in different states. \n",
    "<br>\n",
    "    \n",
    "*    2- Having identified the city, state, and country, the latitude and longitude must be extracted from a complimentary dataset containing the needed information, using a join method on city+state+country as the unique ID.\n",
    "<br>\n",
    "*    3- A good portion of the missing date_time data can be extracted from stats. This field then needs to be converted to a standard format.\n",
    "<br>\n",
    "    \n",
    "*    4- The field duration needs to be converted to seconds. \n",
    "* Note:  some missing values in duration and shape could theoritically be identified from the field text. This step will be pursued only if time permits.\n",
    "<br>\n",
    "    \n",
    "*    5- The country entries need to be formated according to ISO format.\n",
    "<br>\n",
    "    \n",
    "*    6- Finally the useless fields (such as report_link, and posted) must be dropped, and the leftover null values must be replaced by \"unknown\". The transformed data can then be saved into a new csv file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e9937b",
   "metadata": {},
   "source": [
    "### Before starting the data cleaning, I need to make a few supplimentary variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8f050c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert abbreviated states to full name because in the Worldcities table (which will be used later to find the missing lat/long coordinates) the states and provinces are written in non-abbreviated format.\n",
    "\n",
    "us_state_abbr = {\n",
    "    'AL': 'Alabama',\n",
    "    'AK': 'Alaska',\n",
    "    'AZ': 'Arizona',\n",
    "    'AR': 'Arkansas',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'IA': 'Iowa',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi',\n",
    "    'MO': 'Missouri',\n",
    "    'MT': 'Montana',\n",
    "    'NE': 'Nebraska',\n",
    "    'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NY': 'New York',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VT': 'Vermont',\n",
    "    'VA': 'Virginia',\n",
    "    'WA': 'Washington',\n",
    "    'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WY': 'Wyoming'}\n",
    "\n",
    "can_prov_abbr={\n",
    "  'AB': 'Alberta',\n",
    "  'BC': 'British Columbia',\n",
    "  'MB': 'Manitoba',\n",
    "  'NB': 'New Brunswick',\n",
    "  'NL': 'Newfoundland and Labrador',\n",
    "  'NS': 'Nova Scotia',\n",
    "  'NT': 'Northwest Territories',\n",
    "  'NU': 'Nunavut',\n",
    "  'ON': 'Ontario',\n",
    "  'PE': 'Prince Edward Island',\n",
    "  'QC': 'Quebec',\n",
    "  'SK': 'Saskatchewan',\n",
    "  'YT': 'Yukon'\n",
    "}\n",
    "\n",
    "        \n",
    "us_state_can_prov_abbr=us_state_abbr.copy()\n",
    "us_state_can_prov_abbr.update(can_prov_abbr)\n",
    "\n",
    "\n",
    "        \n",
    "def state_fullname(state_abr,state_dict):\n",
    "    \n",
    "        try:\n",
    "            state_full=state_dict[state_abr]\n",
    "        except:\n",
    "            state_full=\"unknown\"\n",
    "            \n",
    "        return state_full\n",
    "    \n",
    "df_ufo['state'] = df_ufo.apply(lambda row: state_fullname(row['state'],us_state_can_prov_abbr),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "741af5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll clean up the city column\n",
    "\n",
    "#1-For convinience of text processing I'll first convert all string fields into english and lower case\n",
    "\n",
    "df_ufo['summary']=df_ufo['summary'].str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "df_ufo['city']=df_ufo['city'].str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "df_ufo['state']=df_ufo['state'].str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "df_ufo['date_time']=df_ufo['date_time'].str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "df_ufo['shape']=df_ufo['shape'].str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "df_ufo['duration']=df_ufo['duration'].str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "df_ufo['stats']=df_ufo['stats'].str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "\n",
    "#Similarly for the world cities dataset (admin_name=Province/State):\n",
    "df_worldcities['city_ascii']=df_worldcities['city_ascii'].str.lower()\n",
    "df_worldcities['country']=df_worldcities['country'].str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "df_worldcities['admin_name']=df_worldcities['admin_name'].str.encode('ascii', errors='ignore').str.decode('utf-8').str.lower()\n",
    "\n",
    "df_worldcities['city_state_country']=df_worldcities['city_ascii']+\" \"+df_worldcities['admin_name']+\" \"+df_worldcities['country']\n",
    "df_worldcities['city_country']=df_worldcities['city_ascii']+\" \"+df_worldcities['country']\n",
    "df_worldcities['city_state']= df_worldcities['city_ascii']+\" \"+df_worldcities['admin_name']\n",
    "\n",
    "# I add a country column and a population column to be filled later\n",
    "df_ufo['country']=\"\"\n",
    "df_ufo['population']=\"\"\n",
    "df_ufo['city_corrected']=\"\"\n",
    "df_ufo['date_time_from_stats']=\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df76c64a",
   "metadata": {},
   "source": [
    "### Now, let's check whether the combination of city, state, and country can uniqly identify the different locations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe26cf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_state_country</th>\n",
       "      <th>COUNT(city_country)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abasolo guanajuato mexico</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abbeville louisiana united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aberdeen washington united states</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abilene texas united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abington pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>yuzawa akita japan</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>zarechnyy penzenskaya oblast russia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>zebbug ebbu malta</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>zheleznogorsk kurskaya oblast russia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>zhijiang hubei china</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1074 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        city_state_country  COUNT(city_country)\n",
       "0                abasolo guanajuato mexico                    2\n",
       "1        abbeville louisiana united states                    2\n",
       "2        aberdeen washington united states                    5\n",
       "3              abilene texas united states                    2\n",
       "4      abington pennsylvania united states                    2\n",
       "...                                    ...                  ...\n",
       "1069                    yuzawa akita japan                    2\n",
       "1070   zarechnyy penzenskaya oblast russia                    2\n",
       "1071                     zebbug ebbu malta                    2\n",
       "1072  zheleznogorsk kurskaya oblast russia                    2\n",
       "1073                  zhijiang hubei china                    2\n",
       "\n",
       "[1074 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query='SELECT city_state_country, COUNT(city_country) FROM df_worldcities GROUP BY city_country HAVING COUNT(city_country) > 1 '\n",
    "pysql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53eada70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_country</th>\n",
       "      <th>COUNT(city_country)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aberdeen united states</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albany united states</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alexandria united states</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpine united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alton united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>winslow united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>woodbury united states</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>woodstock united states</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>wyoming united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>york united states</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 city_country  COUNT(city_country)\n",
       "0      aberdeen united states                    5\n",
       "1        albany united states                    4\n",
       "2    alexandria united states                    4\n",
       "3        alpine united states                    3\n",
       "4         alton united states                    3\n",
       "..                        ...                  ...\n",
       "360     winslow united states                    3\n",
       "361    woodbury united states                    5\n",
       "362   woodstock united states                    5\n",
       "363     wyoming united states                    3\n",
       "364        york united states                    4\n",
       "\n",
       "[365 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query='SELECT city_country, COUNT(city_country) FROM df_worldcities GROUP BY city_country HAVING (COUNT(city_country)>1 AND SUM(lat)<>(AVG(lat)*2)) '\n",
    "pysql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a334141b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_state_country</th>\n",
       "      <th>COUNT(city_state_country)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adams township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allegheny township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bethel township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cam ranh khnh ha vietnam</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>carroll township pennsylvania united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>center township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>conewago township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>derry township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fairview township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>franklin township new jersey united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gaoua sud-ouest burkina faso</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hamilton township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hanover township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hechi guangxi china</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hopewell township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ibb ibb yemen</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jackson township pennsylvania united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>koronadal south cotabato philippines</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>middletown pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>middletown township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mocuba zambzia mozambique</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>montgomery township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>neustadt bavaria germany</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>oruro oruro bolivia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>penn township pennsylvania united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pine township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>richland township pennsylvania united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ross township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rustavi kvemo kartli georgia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>salisbury township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>scott township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>southampton township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>spring township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>springfield township pennsylvania united states</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tabuk kalinga philippines</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>warwick township pennsylvania united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>washington township new jersey united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>washington township pennsylvania united states</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>woodbury new york united states</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>yeosu jeonnam korea, south</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>yiyang hunan china</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 city_state_country  COUNT(city_state_country)\n",
       "0         adams township pennsylvania united states                          2\n",
       "1     allegheny township pennsylvania united states                          2\n",
       "2        bethel township pennsylvania united states                          2\n",
       "3                          cam ranh khnh ha vietnam                          2\n",
       "4       carroll township pennsylvania united states                          3\n",
       "5        center township pennsylvania united states                          2\n",
       "6      conewago township pennsylvania united states                          2\n",
       "7         derry township pennsylvania united states                          2\n",
       "8      fairview township pennsylvania united states                          2\n",
       "9        franklin township new jersey united states                          2\n",
       "10                     gaoua sud-ouest burkina faso                          2\n",
       "11     hamilton township pennsylvania united states                          2\n",
       "12      hanover township pennsylvania united states                          2\n",
       "13                              hechi guangxi china                          2\n",
       "14     hopewell township pennsylvania united states                          2\n",
       "15                                    ibb ibb yemen                          2\n",
       "16      jackson township pennsylvania united states                          3\n",
       "17             koronadal south cotabato philippines                          2\n",
       "18            middletown pennsylvania united states                          2\n",
       "19   middletown township pennsylvania united states                          2\n",
       "20                        mocuba zambzia mozambique                          2\n",
       "21   montgomery township pennsylvania united states                          2\n",
       "22                         neustadt bavaria germany                          2\n",
       "23                              oruro oruro bolivia                          2\n",
       "24         penn township pennsylvania united states                          3\n",
       "25         pine township pennsylvania united states                          2\n",
       "26     richland township pennsylvania united states                          3\n",
       "27         ross township pennsylvania united states                          2\n",
       "28                     rustavi kvemo kartli georgia                          2\n",
       "29    salisbury township pennsylvania united states                          2\n",
       "30        scott township pennsylvania united states                          2\n",
       "31  southampton township pennsylvania united states                          2\n",
       "32       spring township pennsylvania united states                          2\n",
       "33  springfield township pennsylvania united states                          4\n",
       "34                        tabuk kalinga philippines                          2\n",
       "35      warwick township pennsylvania united states                          2\n",
       "36     washington township new jersey united states                          3\n",
       "37   washington township pennsylvania united states                          4\n",
       "38                  woodbury new york united states                          2\n",
       "39                       yeosu jeonnam korea, south                          2\n",
       "40                               yiyang hunan china                          2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query='SELECT city_state_country, COUNT(city_state_country) FROM df_worldcities GROUP BY city_state_country HAVING COUNT(city_state_country)>1 '\n",
    "pysql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ebd7351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_state_country</th>\n",
       "      <th>COUNT(city_state_country)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carroll township pennsylvania united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jackson township pennsylvania united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>penn township pennsylvania united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>richland township pennsylvania united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>springfield township pennsylvania united states</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>washington township new jersey united states</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>washington township pennsylvania united states</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                city_state_country  COUNT(city_state_country)\n",
       "0      carroll township pennsylvania united states                          3\n",
       "1      jackson township pennsylvania united states                          3\n",
       "2         penn township pennsylvania united states                          3\n",
       "3     richland township pennsylvania united states                          3\n",
       "4  springfield township pennsylvania united states                          4\n",
       "5     washington township new jersey united states                          3\n",
       "6   washington township pennsylvania united states                          4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query='SELECT city_state_country, COUNT(city_state_country) FROM df_worldcities GROUP BY city_state_country HAVING (COUNT(city_state_country)>1 AND SUM(lat)<>(AVG(lat)*2)) '\n",
    "pysql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f3b5961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.3774</td>\n",
       "      <td>-76.3142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.9057</td>\n",
       "      <td>-76.8796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0080</td>\n",
       "      <td>-75.3578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lat      lng\n",
       "0  40.3774 -76.3142\n",
       "1  39.9057 -76.8796\n",
       "2  41.0080 -75.3578"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query='select lat,lng from df_worldcities where city_state_country=\"jackson township pennsylvania united states\" '\n",
    "pysql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea9ada",
   "metadata": {},
   "source": [
    "\n",
    " * Finding: \n",
    " \n",
    "The results of above queries show that city+country can not identify the location uniquely (there are 365 similar combinations with different latitudes), but city+state+country can. Although for this combination still there are 6 similar records with different latitudes, but seemingly these are duplicate of same record because their coordinates are very close."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f3dde",
   "metadata": {},
   "source": [
    "# Now, let's begin the cleaning process:\n",
    "\n",
    "## Step 1:\n",
    "### The missing/messy values of city, state and country (new field to be added to the table) must be extracted from stats where possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d2bfce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary of keys=country, value=cities, for all the world countries. This dictionary will be used to faster look for the city once we identified the country (in the next script).\n",
    "\n",
    "list_of_countries=df_worldcities.country.unique()\n",
    "dict_country_city={}\n",
    "dict_city_state={}\n",
    "dict_country_city_state={}\n",
    "for country in list_of_countries:\n",
    "    list_of_cities=df_worldcities.loc[df_worldcities['country'] ==country, 'city_ascii'].values\n",
    "    dict_country_city[country]=list_of_cities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f62efa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, clean the mixed entries for which both city and country name exist in the city field:\n",
    "\n",
    "\n",
    "def find_missing_locationinfo(city_original,stats,state_original,dict_country_city,us_state_abbr,can_prov_abbr,df_worldcities):\n",
    "\n",
    "\n",
    "    identified_country=\"\"\n",
    "    pattern = re.compile(\"[^a-z A-Z]\")\n",
    "    try:\n",
    "        x=pattern.search(city_original) is not None\n",
    "    except:\n",
    "        x=0\n",
    "        \n",
    "# for the city mixed entries let's first fix UK-variation issue:['uk/england','uk/scotland',' uk/wales', 'uk/englnd','uk/birmingham','uk/endland','uk/enland'],and also remove ()_,/  \n",
    "# for the non mixed cities: if we have both the city and the state the location can be identified, otherwise not (because there are some cities with same name in different states): for such records the coordinates, if existed, could be used for state identification, but I have already checked and know that there is no entry with null state and not-null coordinates.\n",
    "\n",
    "    \n",
    "    if x:\n",
    "        try:\n",
    "            start=stats.split().index('location:')\n",
    "            end=stats.split().index('shape:')\n",
    "            location_info_list=[i+\" \" for i in stats.split()[start+1:end]]\n",
    "            location_info_str=''.join(location_info_list)\n",
    "            location_info_str=location_info_str.replace('uk/england','united kingdom').replace('uk/scotland','united kingdom').replace('uk/wales','united kingdom').replace('uk/englnd','united kingdom').replace('uk/birmingham','united kingdom').replace('uk/endland','united kingdom').replace('uk/enland','united kingdom')\n",
    "            location_info_str=location_info_str.replace(\"(\",\" \").replace(\")\",\" \").replace(\",\",\" \").replace(\"/\",\" \").replace(\"_\",\" \")\n",
    "            \n",
    "# Identify the country:\n",
    "            for country in list_of_countries:\n",
    "               if country in location_info_str:\n",
    "                  identified_country=country\n",
    "                  \n",
    "                \n",
    " #Then, if the country is identified, find the city, otherwise record unknown. If city identified, find the state (admin_name in the df_worldcities table)  \n",
    "        \n",
    "            if  len(identified_country)>1:\n",
    "               \n",
    "                for city in dict_country_city[identified_country]:\n",
    "                    if city in location_info_str:\n",
    "                        city_corrected=city\n",
    "                    \n",
    "                if  len(city_corrected)>1 :  \n",
    "                    if len(df_worldcities.loc[df_worldcities['city_country']==city_corrected+\" \"+identified_country,'admin_name'].values)==1:\n",
    "                        state_corrected=df_worldcities.loc[df_worldcities['city_country']==city_corrected+\" \"+identified_country,'admin_name'].values[0]\n",
    "                    else:\n",
    "                        state_corrected='unknown'  \n",
    "                else:\n",
    "                    city_corrected='unknown'\n",
    "                    state_corrected='unknown'\n",
    "                \n",
    "            \n",
    "            else:\n",
    "                city_corrected='unknown'\n",
    "                state_corrected='unknown'\n",
    "                identified_country='unknown'\n",
    "         \n",
    "        \n",
    "        except:\n",
    "            city_corrected='unknown'\n",
    "            state_corrected='unknown'\n",
    "            identified_country='unknown'       \n",
    "                    \n",
    "# Second, clean the non-mixed entries for city:                        \n",
    "    else:\n",
    "         \n",
    "        if state_original is not None and city_original is not None:\n",
    "            try:\n",
    "                city_corrected=city_original\n",
    "                state_corrected=state_original\n",
    "                if state_original.title() in us_state_abbr.values():\n",
    "                    identified_country='united states'          \n",
    "                elif state_original.title() in can_prov_abbr.values():\n",
    "                    identified_country='canada'\n",
    "            except:\n",
    "                 identified_country= \"unknown\"\n",
    "        else:\n",
    "             identified_country= \"unknown\"\n",
    "                \n",
    "                \n",
    "    #return city_corrected\n",
    "#df_ufo['city_corrected'] =df_ufo.apply(lambda row: find_missing_locationinfo(row['city'],row['stats'],row['state'],dict_country_city,us_state_abbr,can_prov_abbr,df_worldcities), axis=1)\n",
    "\n",
    "    #return state_corrected\n",
    "#df_ufo['state'] =df_ufo.apply(lambda row: find_missing_locationinfo(row['city'],row['stats'],row['state'],dict_country_city,us_state_abbr,can_prov_abbr,df_worldcities), axis=1)   \n",
    "    \n",
    "    #return identified_country\n",
    "#df_ufo['country'] =df_ufo.apply(lambda row: find_missing_locationinfo(row['city'],row['stats'],row['state'],dict_country_city,us_state_abbr,can_prov_abbr,df_worldcities), axis=1)\n",
    "\n",
    "\n",
    "     return city_corrected, state_corrected, identified_country\n",
    "df_ufo['city_corrected','state','country'] =df_ufo.apply(lambda row: find_missing_locationinfo(row['city'],row['stats'],row['state'],dict_country_city,us_state_abbr,can_prov_abbr,df_worldcities), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f38a90f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>date_time</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration</th>\n",
       "      <th>stats</th>\n",
       "      <th>report_link</th>\n",
       "      <th>text</th>\n",
       "      <th>posted</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>city_corrected</th>\n",
       "      <th>date_time_from_stats</th>\n",
       "      <th>city_state_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my wife was driving southeast on a fairly popu...</td>\n",
       "      <td>chester</td>\n",
       "      <td>virginia</td>\n",
       "      <td>2019-12-12t18:43:00</td>\n",
       "      <td>light</td>\n",
       "      <td>5 seconds</td>\n",
       "      <td>occurred : 12/12/2019 18:43  (entered as : 12/...</td>\n",
       "      <td>http://www.nuforc.org/webreports/151/S151739.html</td>\n",
       "      <td>My wife was driving southeast on a fairly popu...</td>\n",
       "      <td>2019-12-22T00:00:00</td>\n",
       "      <td>37.343152</td>\n",
       "      <td>-77.408582</td>\n",
       "      <td>united states</td>\n",
       "      <td></td>\n",
       "      <td>chester</td>\n",
       "      <td></td>\n",
       "      <td>chester virginia united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i think that i may caught a ufo on the nbc nig...</td>\n",
       "      <td>rocky hill</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>2019-03-22t18:30:00</td>\n",
       "      <td>circle</td>\n",
       "      <td>3-5 seconds</td>\n",
       "      <td>occurred : 3/22/2019 18:30  (entered as : 03/2...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145297.html</td>\n",
       "      <td>I think that I may caught a UFO on the NBC Nig...</td>\n",
       "      <td>2019-03-29T00:00:00</td>\n",
       "      <td>41.664800</td>\n",
       "      <td>-72.639300</td>\n",
       "      <td>united states</td>\n",
       "      <td></td>\n",
       "      <td>rocky hill</td>\n",
       "      <td></td>\n",
       "      <td>rocky hill connecticut united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i woke up late in the afternoon 3:30-4pm. i we...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>occurred : 4/1/2019 15:45  (entered as : april...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145556.html</td>\n",
       "      <td>I woke up late in the afternoon 3:30-4pm.  I w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was driving towards the intersection of fall...</td>\n",
       "      <td>ottawa</td>\n",
       "      <td>ontario</td>\n",
       "      <td>2019-04-17t02:00:00</td>\n",
       "      <td>teardrop</td>\n",
       "      <td>10 seconds</td>\n",
       "      <td>occurred : 4/17/2019 02:00  (entered as : 04-1...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145697.html</td>\n",
       "      <td>I was driving towards the intersection of fall...</td>\n",
       "      <td>2019-04-18T00:00:00</td>\n",
       "      <td>45.381383</td>\n",
       "      <td>-75.708501</td>\n",
       "      <td>canada</td>\n",
       "      <td></td>\n",
       "      <td>ottawa</td>\n",
       "      <td></td>\n",
       "      <td>ottawa ontario canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in peoria arizona, i saw a cigar shaped craft ...</td>\n",
       "      <td>peoria</td>\n",
       "      <td>new york</td>\n",
       "      <td>2009-03-15t18:00:00</td>\n",
       "      <td>cigar</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>occurred : 3/15/2009 18:00  (entered as : 03/1...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145723.html</td>\n",
       "      <td>In Peoria, Arizona, I saw a cigar shaped craft...</td>\n",
       "      <td>2019-04-18T00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td></td>\n",
       "      <td>peoria</td>\n",
       "      <td></td>\n",
       "      <td>peoria new york united states</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary        city        state  \\\n",
       "0  my wife was driving southeast on a fairly popu...     chester     virginia   \n",
       "1  i think that i may caught a ufo on the nbc nig...  rocky hill  connecticut   \n",
       "2  i woke up late in the afternoon 3:30-4pm. i we...         NaN      unknown   \n",
       "3  i was driving towards the intersection of fall...      ottawa      ontario   \n",
       "4  in peoria arizona, i saw a cigar shaped craft ...      peoria     new york   \n",
       "\n",
       "             date_time     shape     duration  \\\n",
       "0  2019-12-12t18:43:00     light    5 seconds   \n",
       "1  2019-03-22t18:30:00    circle  3-5 seconds   \n",
       "2                  NaN       NaN          NaN   \n",
       "3  2019-04-17t02:00:00  teardrop   10 seconds   \n",
       "4  2009-03-15t18:00:00     cigar    2 minutes   \n",
       "\n",
       "                                               stats  \\\n",
       "0  occurred : 12/12/2019 18:43  (entered as : 12/...   \n",
       "1  occurred : 3/22/2019 18:30  (entered as : 03/2...   \n",
       "2  occurred : 4/1/2019 15:45  (entered as : april...   \n",
       "3  occurred : 4/17/2019 02:00  (entered as : 04-1...   \n",
       "4  occurred : 3/15/2009 18:00  (entered as : 03/1...   \n",
       "\n",
       "                                         report_link  \\\n",
       "0  http://www.nuforc.org/webreports/151/S151739.html   \n",
       "1  http://www.nuforc.org/webreports/145/S145297.html   \n",
       "2  http://www.nuforc.org/webreports/145/S145556.html   \n",
       "3  http://www.nuforc.org/webreports/145/S145697.html   \n",
       "4  http://www.nuforc.org/webreports/145/S145723.html   \n",
       "\n",
       "                                                text               posted  \\\n",
       "0  My wife was driving southeast on a fairly popu...  2019-12-22T00:00:00   \n",
       "1  I think that I may caught a UFO on the NBC Nig...  2019-03-29T00:00:00   \n",
       "2  I woke up late in the afternoon 3:30-4pm.  I w...                  NaN   \n",
       "3  I was driving towards the intersection of fall...  2019-04-18T00:00:00   \n",
       "4  In Peoria, Arizona, I saw a cigar shaped craft...  2019-04-18T00:00:00   \n",
       "\n",
       "   city_latitude  city_longitude        country population city_corrected  \\\n",
       "0      37.343152      -77.408582  united states                   chester   \n",
       "1      41.664800      -72.639300  united states                rocky hill   \n",
       "2            NaN             NaN                                      NaN   \n",
       "3      45.381383      -75.708501         canada                    ottawa   \n",
       "4            NaN             NaN  united states                    peoria   \n",
       "\n",
       "  date_time_from_stats                    city_state_country  \n",
       "0                             chester virginia united states  \n",
       "1                       rocky hill connecticut united states  \n",
       "2                                                        NaN  \n",
       "3                                      ottawa ontario canada  \n",
       "4                              peoria new york united states  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Record the unique combination of city/state/country name to be used for the identification of long/lat coordinates in the next step:\n",
    "\n",
    "df_ufo['city_state_country']=df_ufo['city_corrected']+\" \"+df_ufo['state']+\" \"+df_ufo['country']\n",
    "df_ufo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3501c97d",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "\n",
    "### Having identified the city, state, and country, the latitude and longitude must be identified from a complimentary dataset (df_worldcities).\n",
    "\n",
    "### I will also identify and save the population information wherever possible, as it might be useful later for the normalization of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b13fe",
   "metadata": {},
   "source": [
    "**Note**:  \n",
    "<br>\n",
    "The next script is relatively slow due to the type of itteration. A faster way of doing it would be through this single line: df_new_ufo=df_ufo.merge(df_worldcities, on='city_state_country', how='left',indicator=True) , i.e. left join (df_ufo being left) on the unique location key (being:city_state_country).  The equivalent SQL query would be: query='select wc.population, wc.lat, wc.lng from df_ufo as ufo left join df_worldcities as wc on ufo.city+state+country=wc.city+state+country). However, the reason that I'm not doing it this way is that the city+state+country is not perfectly unique in the df_worldcitie table (as there are some seemingly re-enties). Removing the duplicates require certain information which I didn't have. To simplify the process, I proceeded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55fd4fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>date_time</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration</th>\n",
       "      <th>stats</th>\n",
       "      <th>report_link</th>\n",
       "      <th>text</th>\n",
       "      <th>posted</th>\n",
       "      <th>city_latitude</th>\n",
       "      <th>city_longitude</th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>city_corrected</th>\n",
       "      <th>date_time_from_stats</th>\n",
       "      <th>city_state_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my wife was driving southeast on a fairly popu...</td>\n",
       "      <td>chester</td>\n",
       "      <td>virginia</td>\n",
       "      <td>2019-12-12t18:43:00</td>\n",
       "      <td>light</td>\n",
       "      <td>5 seconds</td>\n",
       "      <td>occurred : 12/12/2019 18:43  (entered as : 12/...</td>\n",
       "      <td>http://www.nuforc.org/webreports/151/S151739.html</td>\n",
       "      <td>My wife was driving southeast on a fairly popu...</td>\n",
       "      <td>2019-12-22T00:00:00</td>\n",
       "      <td>37.3531</td>\n",
       "      <td>-77.4342</td>\n",
       "      <td>united states</td>\n",
       "      <td>22144.0</td>\n",
       "      <td>chester</td>\n",
       "      <td></td>\n",
       "      <td>chester virginia united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i think that i may caught a ufo on the nbc nig...</td>\n",
       "      <td>rocky hill</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>2019-03-22t18:30:00</td>\n",
       "      <td>circle</td>\n",
       "      <td>3-5 seconds</td>\n",
       "      <td>occurred : 3/22/2019 18:30  (entered as : 03/2...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145297.html</td>\n",
       "      <td>I think that I may caught a UFO on the NBC Nig...</td>\n",
       "      <td>2019-03-29T00:00:00</td>\n",
       "      <td>41.6572</td>\n",
       "      <td>-72.6632</td>\n",
       "      <td>united states</td>\n",
       "      <td>20137.0</td>\n",
       "      <td>rocky hill</td>\n",
       "      <td></td>\n",
       "      <td>rocky hill connecticut united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i woke up late in the afternoon 3:30-4pm. i we...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>occurred : 4/1/2019 15:45  (entered as : april...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145556.html</td>\n",
       "      <td>I woke up late in the afternoon 3:30-4pm.  I w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was driving towards the intersection of fall...</td>\n",
       "      <td>ottawa</td>\n",
       "      <td>ontario</td>\n",
       "      <td>2019-04-17t02:00:00</td>\n",
       "      <td>teardrop</td>\n",
       "      <td>10 seconds</td>\n",
       "      <td>occurred : 4/17/2019 02:00  (entered as : 04-1...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145697.html</td>\n",
       "      <td>I was driving towards the intersection of fall...</td>\n",
       "      <td>2019-04-18T00:00:00</td>\n",
       "      <td>45.4247</td>\n",
       "      <td>-75.695</td>\n",
       "      <td>canada</td>\n",
       "      <td>989567.0</td>\n",
       "      <td>ottawa</td>\n",
       "      <td></td>\n",
       "      <td>ottawa ontario canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in peoria arizona, i saw a cigar shaped craft ...</td>\n",
       "      <td>peoria</td>\n",
       "      <td>new york</td>\n",
       "      <td>2009-03-15t18:00:00</td>\n",
       "      <td>cigar</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>occurred : 3/15/2009 18:00  (entered as : 03/1...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145723.html</td>\n",
       "      <td>In Peoria, Arizona, I saw a cigar shaped craft...</td>\n",
       "      <td>2019-04-18T00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states</td>\n",
       "      <td></td>\n",
       "      <td>peoria</td>\n",
       "      <td></td>\n",
       "      <td>peoria new york united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the object has flashing lights that are green,...</td>\n",
       "      <td>kirbyville</td>\n",
       "      <td>texas</td>\n",
       "      <td>2019-04-02t20:25:00</td>\n",
       "      <td>disk</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>occurred : 4/2/2019 20:25  (entered as : 04/02...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145476.html</td>\n",
       "      <td>The object has flashing lights that are green,...</td>\n",
       "      <td>2019-04-08T00:00:00</td>\n",
       "      <td>30.6772</td>\n",
       "      <td>-94.0052</td>\n",
       "      <td>united states</td>\n",
       "      <td></td>\n",
       "      <td>kirbyville</td>\n",
       "      <td></td>\n",
       "      <td>kirbyville texas united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>description is the same as washington dc event...</td>\n",
       "      <td>tucson</td>\n",
       "      <td>arizona</td>\n",
       "      <td>2019-05-01t11:00:00</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>occurred : 5/1/2019 11:00  (entered as : 5/1/1...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145947.html</td>\n",
       "      <td>Description is the same as Washington, DC, eve...</td>\n",
       "      <td>2019-05-09T00:00:00</td>\n",
       "      <td>32.1545</td>\n",
       "      <td>-110.8782</td>\n",
       "      <td>united states</td>\n",
       "      <td>888486.0</td>\n",
       "      <td>tucson</td>\n",
       "      <td></td>\n",
       "      <td>tucson arizona united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apr. 10th we witnessed a very bright silvery r...</td>\n",
       "      <td>gold canyon</td>\n",
       "      <td>arizona</td>\n",
       "      <td>2019-04-10t17:00:00</td>\n",
       "      <td>circle</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>occurred : 4/10/2019 17:00  (entered as : 04/1...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145766.html</td>\n",
       "      <td>Apr. 10th we witnessed a very bright silvery r...</td>\n",
       "      <td>2019-04-25T00:00:00</td>\n",
       "      <td>33.3715</td>\n",
       "      <td>-111.4369</td>\n",
       "      <td>united states</td>\n",
       "      <td>11038.0</td>\n",
       "      <td>gold canyon</td>\n",
       "      <td></td>\n",
       "      <td>gold canyon arizona united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ufos report in irving texas at 2200 hrs. on or...</td>\n",
       "      <td>dallas</td>\n",
       "      <td>texas</td>\n",
       "      <td>1973-07-14t22:00:00</td>\n",
       "      <td>oval</td>\n",
       "      <td>6 minutes</td>\n",
       "      <td>occurred : 7/14/1973 22:00  (entered as : 07/1...</td>\n",
       "      <td>http://www.nuforc.org/webreports/145/S145751.html</td>\n",
       "      <td>Ufos report in Irving Texas at 2200 hrs.  On o...</td>\n",
       "      <td>2019-04-25T00:00:00</td>\n",
       "      <td>32.7936</td>\n",
       "      <td>-96.7662</td>\n",
       "      <td>united states</td>\n",
       "      <td>5743938.0</td>\n",
       "      <td>dallas</td>\n",
       "      <td></td>\n",
       "      <td>dallas texas united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>group of lights formation sweeping thru a nigh...</td>\n",
       "      <td>caloocan city (philippines)</td>\n",
       "      <td>caloocan</td>\n",
       "      <td>2019-06-06t19:00:00</td>\n",
       "      <td>other</td>\n",
       "      <td>19:00 to 19:30</td>\n",
       "      <td>occurred : 6/6/2019 19:00  (entered as : 6/6/2...</td>\n",
       "      <td>http://www.nuforc.org/webreports/146/S146694.html</td>\n",
       "      <td>group of lights formation sweeping thru a nigh...</td>\n",
       "      <td>2019-06-07T00:00:00</td>\n",
       "      <td>14.65</td>\n",
       "      <td>120.9667</td>\n",
       "      <td>philippines</td>\n",
       "      <td>1583978.0</td>\n",
       "      <td>caloocan city</td>\n",
       "      <td></td>\n",
       "      <td>caloocan city caloocan philippines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  my wife was driving southeast on a fairly popu...   \n",
       "1  i think that i may caught a ufo on the nbc nig...   \n",
       "2  i woke up late in the afternoon 3:30-4pm. i we...   \n",
       "3  i was driving towards the intersection of fall...   \n",
       "4  in peoria arizona, i saw a cigar shaped craft ...   \n",
       "5  the object has flashing lights that are green,...   \n",
       "6  description is the same as washington dc event...   \n",
       "7  apr. 10th we witnessed a very bright silvery r...   \n",
       "8  ufos report in irving texas at 2200 hrs. on or...   \n",
       "9  group of lights formation sweeping thru a nigh...   \n",
       "\n",
       "                          city        state            date_time     shape  \\\n",
       "0                      chester     virginia  2019-12-12t18:43:00     light   \n",
       "1                   rocky hill  connecticut  2019-03-22t18:30:00    circle   \n",
       "2                          NaN      unknown                  NaN       NaN   \n",
       "3                       ottawa      ontario  2019-04-17t02:00:00  teardrop   \n",
       "4                       peoria     new york  2009-03-15t18:00:00     cigar   \n",
       "5                   kirbyville        texas  2019-04-02t20:25:00      disk   \n",
       "6                       tucson      arizona  2019-05-01t11:00:00   unknown   \n",
       "7                  gold canyon      arizona  2019-04-10t17:00:00    circle   \n",
       "8                       dallas        texas  1973-07-14t22:00:00      oval   \n",
       "9  caloocan city (philippines)     caloocan  2019-06-06t19:00:00     other   \n",
       "\n",
       "         duration                                              stats  \\\n",
       "0       5 seconds  occurred : 12/12/2019 18:43  (entered as : 12/...   \n",
       "1     3-5 seconds  occurred : 3/22/2019 18:30  (entered as : 03/2...   \n",
       "2             NaN  occurred : 4/1/2019 15:45  (entered as : april...   \n",
       "3      10 seconds  occurred : 4/17/2019 02:00  (entered as : 04-1...   \n",
       "4       2 minutes  occurred : 3/15/2009 18:00  (entered as : 03/1...   \n",
       "5      15 minutes  occurred : 4/2/2019 20:25  (entered as : 04/02...   \n",
       "6       5 minutes  occurred : 5/1/2019 11:00  (entered as : 5/1/1...   \n",
       "7      10 minutes  occurred : 4/10/2019 17:00  (entered as : 04/1...   \n",
       "8       6 minutes  occurred : 7/14/1973 22:00  (entered as : 07/1...   \n",
       "9  19:00 to 19:30  occurred : 6/6/2019 19:00  (entered as : 6/6/2...   \n",
       "\n",
       "                                         report_link  \\\n",
       "0  http://www.nuforc.org/webreports/151/S151739.html   \n",
       "1  http://www.nuforc.org/webreports/145/S145297.html   \n",
       "2  http://www.nuforc.org/webreports/145/S145556.html   \n",
       "3  http://www.nuforc.org/webreports/145/S145697.html   \n",
       "4  http://www.nuforc.org/webreports/145/S145723.html   \n",
       "5  http://www.nuforc.org/webreports/145/S145476.html   \n",
       "6  http://www.nuforc.org/webreports/145/S145947.html   \n",
       "7  http://www.nuforc.org/webreports/145/S145766.html   \n",
       "8  http://www.nuforc.org/webreports/145/S145751.html   \n",
       "9  http://www.nuforc.org/webreports/146/S146694.html   \n",
       "\n",
       "                                                text               posted  \\\n",
       "0  My wife was driving southeast on a fairly popu...  2019-12-22T00:00:00   \n",
       "1  I think that I may caught a UFO on the NBC Nig...  2019-03-29T00:00:00   \n",
       "2  I woke up late in the afternoon 3:30-4pm.  I w...                  NaN   \n",
       "3  I was driving towards the intersection of fall...  2019-04-18T00:00:00   \n",
       "4  In Peoria, Arizona, I saw a cigar shaped craft...  2019-04-18T00:00:00   \n",
       "5  The object has flashing lights that are green,...  2019-04-08T00:00:00   \n",
       "6  Description is the same as Washington, DC, eve...  2019-05-09T00:00:00   \n",
       "7  Apr. 10th we witnessed a very bright silvery r...  2019-04-25T00:00:00   \n",
       "8  Ufos report in Irving Texas at 2200 hrs.  On o...  2019-04-25T00:00:00   \n",
       "9  group of lights formation sweeping thru a nigh...  2019-06-07T00:00:00   \n",
       "\n",
       "  city_latitude city_longitude        country population city_corrected  \\\n",
       "0       37.3531       -77.4342  united states    22144.0        chester   \n",
       "1       41.6572       -72.6632  united states    20137.0     rocky hill   \n",
       "2       unknown        unknown                   unknown            NaN   \n",
       "3       45.4247        -75.695         canada   989567.0         ottawa   \n",
       "4           NaN            NaN  united states                    peoria   \n",
       "5       30.6772       -94.0052  united states                kirbyville   \n",
       "6       32.1545      -110.8782  united states   888486.0         tucson   \n",
       "7       33.3715      -111.4369  united states    11038.0    gold canyon   \n",
       "8       32.7936       -96.7662  united states  5743938.0         dallas   \n",
       "9         14.65       120.9667    philippines  1583978.0  caloocan city   \n",
       "\n",
       "  date_time_from_stats                    city_state_country  \n",
       "0                             chester virginia united states  \n",
       "1                       rocky hill connecticut united states  \n",
       "2                                                        NaN  \n",
       "3                                      ottawa ontario canada  \n",
       "4                              peoria new york united states  \n",
       "5                             kirbyville texas united states  \n",
       "6                               tucson arizona united states  \n",
       "7                          gold canyon arizona united states  \n",
       "8                                 dallas texas united states  \n",
       "9                         caloocan city caloocan philippines  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have Country, state and city for as many records as possible, lets identify all possible lat/long coordinates from unique combination of city/state/country name:\n",
    "\n",
    "pattern = re.compile(\"[a-z A-Z]\")\n",
    "\n",
    "city_state_country_list= list(df_worldcities['city_state_country'])\n",
    "for ind, row in df_ufo.iterrows():\n",
    "\n",
    "    try:\n",
    "        unique_location_identifier=df_ufo.loc[ind,'city_state_country']\n",
    "        if unique_location_identifier in city_state_country_list:\n",
    "        \n",
    "            df_ufo.loc[ind,'city_latitude']=df_worldcities.loc[df_worldcities['city_state_country']==df_ufo.loc[ind,'city_state_country'],'lat'].iloc[0]\n",
    "            df_ufo.loc[ind,'city_longitude']=df_worldcities.loc[df_worldcities['city_state_country']==df_ufo.loc[ind,'city_state_country'],'lng'].iloc[0]\n",
    "            df_ufo.loc[ind,'population']=df_worldcities.loc[df_worldcities['city_state_country']==df_ufo.loc[ind,'city_state_country'],'population'].iloc[0]\n",
    "    except:\n",
    "            df_ufo.loc[ind,'city_latitude']=\"unknown\"\n",
    "            df_ufo.loc[ind,'city_longitude']=\"unknown\"\n",
    "            df_ufo.loc[ind,'population']=\"unknown\"\n",
    "        \n",
    "df_ufo.head(10)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74af17ae",
   "metadata": {},
   "source": [
    "### Checking how many of the original missing values (16112) in city_latitude/longitude were recovered:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33bba925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(city)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(city)\n",
       "0        10340"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    query='select count(city) from df_ufo where city_latitude is null'\n",
    "   # query='select count(city),country from df_ufo where city_latitude is null group by country order by count(city) desc'\n",
    "   # query='select city_corrected, city, state,country from df_ufo where city_latitude is null and country=\"united kingdom\"'\n",
    "   # query='select city_ascii, admin_name,country from df_worldcities where country=\"united kingdom\"'\n",
    "    pysql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27854e2e",
   "metadata": {},
   "source": [
    "#### Finding:\n",
    "\n",
    "   * There are still 10340 missing values. The largest missing values belong to: USA (7223),unidentified country(2683),canada(503), and UK (369). \n",
    "   \n",
    "   <br>\n",
    "   * I checked some of them and realized that for these entries city name is wrong (name of district, or comunity instead of a city, e.g. leyner, colorado,US, and kent,UK). That's why the location couldn't be identified and consequently the latitude/longitude coordinates can not be matched with them.\n",
    "   <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db937e03",
   "metadata": {},
   "source": [
    "## Step 3: \n",
    "\n",
    "### Let's find the missing date_times, and format them.\n",
    "\n",
    "### Missing date_time can be extracted from stats. This field then needs to be converted into a standard format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9871268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, Lets read all the date/times from stats, and change format to iso \n",
    "#then check the date_time, and wherever date_time is missing copy the value of date_time_from_stats in to date_time\n",
    "\n",
    "\n",
    "def missing_date_time_finder(stats,original_date_time):\n",
    "\n",
    "        try:\n",
    "            date_time_str=stats.split()[2]+\"t\"+stats.split()[3]\n",
    "            date_time_obj=datetime.datetime.strptime(date_time_str, '%m/%d/%Yt%H:%M')\n",
    "            date_time_from_stats=date_time_obj.isoformat()\n",
    "        except:\n",
    "            date_time_from_stats=\"\"\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            date_time_existing=original_date_time\n",
    "            date_time_obj=datetime.datetime.strptime(date_time_existing, '%Y-%m-%dt%H:%M:%S')\n",
    "            date_time_formatted=date_time_obj.isoformat()\n",
    "        except:\n",
    "            date_time_formatted=date_time_from_stats\n",
    "        \n",
    "        return  date_time_formatted   \n",
    "\n",
    "df_ufo['date_time'] =df_ufo.apply(lambda row: missing_date_time_finder(row['stats'],row['date_time']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dde051d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(date_time)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(date_time)\n",
       "0             87923"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the editted date_time:\n",
    "query='select count(date_time) from df_ufo where date_time REGEXP \"[0-9a-zA-Z]\"'\n",
    "pysql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52928c4",
   "metadata": {},
   "source": [
    "   * Finding: \n",
    "   <br>\n",
    "\n",
    "After transformation, there are 87923 not null values in the date_time. Which means still 202 values are missing. Two of them can not be recovered because their stats is null too. Those 200 records must have had a different format so that my code couldn't convert them. If time permitted, I would have tried to identify and recover those records too. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f8152c",
   "metadata": {},
   "source": [
    "## Step 4: \n",
    "\n",
    "### Now let's convert the durations into seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70292a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the text duration into seconds\n",
    "def duration_converter(original_duration):\n",
    "    \n",
    "    try:\n",
    "        numeric_duration = durations.Duration(original_duration)\n",
    "        duration_in_seconds=numeric_duration.to_seconds()\n",
    "    except:\n",
    "        duration_in_seconds=\"unknown\"\n",
    "    return duration_in_seconds\n",
    "\n",
    "df_ufo['duration'] =df_ufo.apply(lambda row: duration_converter(row['duration']), axis=1)\n",
    "# Let's check if there is any unreasonable or negative duration:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af775770",
   "metadata": {},
   "source": [
    "  **Note:**  The original non-null entry in duration was equal to 84954. After converting to second, using duration method,  not-null entries of duration decreased to 58548 (missing about %30 of data!). This is because 29577 entries were recorded inaccurately (uncertain or unquantifiable) and hence  couldn't be converted using the duration method. Cleaning those records requires more time and effort which is beyond the scoope of this project.\n",
    "\n",
    "Below you can see some sample queries used in this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "909b3dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count (duration)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count (duration)\n",
       "0             58548"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result of application of duration method on duration data:\n",
    "#query='select duration, duration_second from df_ufo where duration is not null'\n",
    "#query='select count (duration) from df_ufo where duration is not null'\n",
    "query='select count (duration) from df_ufo where duration REGEXP \"[0-9]\"'\n",
    "#query='select duration from df_ufo where duration not REGEXP \"[0-9]\"'\n",
    "pysql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f32706",
   "metadata": {},
   "source": [
    "## Step 5: \n",
    "\n",
    "### Let's format the country entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "688b5be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting countries to iso 3166-1\n",
    "\n",
    "\n",
    "## There are 17 countries whose official name in the pycountry differs from their common name (which is prsented in my data):\n",
    "## therefore to convert them to iso format I have to first substitute their CODE according to pycountry \n",
    "    \n",
    "exception_countries_official_name={\n",
    "    'iran':'IRN',\n",
    "    'venezuela': 'VEN' ,\n",
    "    'reunion':'REU',\n",
    "    'russia': 'RUS' ,\n",
    "    'bolivia': 'BOL' ,\n",
    "    'macedonia': 'MKD' ,\n",
    "    'syria': 'SYR' ,\n",
    "    'brunei': 'BRU' ,\n",
    "    'kosovo': 'UNK' ,\n",
    "    'isle of man': 'IMN' ,\n",
    "    'macau': 'MAC' ,\n",
    "    'tanzania': 'TZA' ,\n",
    "    'taiwan': 'TWN' ,\n",
    "    'west bank': '-' ,\n",
    "    'curaao': 'CUW' ,\n",
    "    'moldova':'MDA',\n",
    "    'vietnam':  'WNM'\n",
    "}\n",
    "    \n",
    "    \n",
    "countries = {}\n",
    "for country in pycountry.countries:\n",
    "        countries[country.name] = country.alpha_2\n",
    "\n",
    "            \n",
    "def country_converter(original_country):\n",
    "  \n",
    "        if original_country in exception_countries_official_name.keys():\n",
    "            formatted_country=exception_countries_official_name[original_country]\n",
    "        else:\n",
    "            title_country=original_country.title()\n",
    "            formatted_country=countries.get(title_country, 'unknown')  \n",
    "            \n",
    "        return formatted_country\n",
    "\n",
    "\n",
    "df_ufo['country_iso'] =df_ufo.apply(lambda row: country_converter(row['country']), axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48ce0a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count (report_link)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count (report_link)\n",
       "0                85048"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query='select count (report_link) from df_ufo where country_iso!=\"unknown\"'\n",
    "pysql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff97ffe2",
   "metadata": {},
   "source": [
    "## Step 6:  \n",
    "\n",
    "### Finally, let's drop the useless fields, replace the leftover null values by \"unknown\", and save the transformed data into a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a734bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the fields that are not useful in data analysis\n",
    "df_ufo_clean=df_ufo.drop([ 'summary','city','report_link','text','posted','city_state_country','date_time_from_stats'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d092a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overwriting the Null values in duration and shape field:\n",
    "df_ufo_clean.loc[df_ufo_clean[\"state\"].isnull(), 'state'] = 'unknown'\n",
    "df_ufo_clean.loc[df_ufo_clean[\"shape\"].isnull(), 'shape'] = 'unknown'\n",
    "df_ufo_clean.loc[df_ufo_clean[\"duration\"].isnull(), 'duration'] = 'unknown'\n",
    "df_ufo_clean.loc[df_ufo_clean[\"date_time\"].isnull(), 'date_time'] = 'unknown'\n",
    "df_ufo_clean.loc[df_ufo_clean[\"city_latitude\"].isnull(), 'city_latitude'] = 'unknown'\n",
    "df_ufo_clean.loc[df_ufo_clean[\"city_longitude\"].isnull(), 'city_longitude'] = 'unknown'\n",
    "df_ufo_clean.loc[df_ufo_clean[\"country\"].isnull(), 'country'] = 'unknown'\n",
    "df_ufo_clean.loc[df_ufo_clean[\"population\"].isnull(), 'population'] = 'unknown'\n",
    "df_ufo_clean.loc[df_ufo_clean[\"city_corrected\"].isnull(), 'city_corrected'] = 'unknown'\n",
    "df_ufo_clean.loc[df_ufo_clean[\"country_iso\"].isnull(), 'country_iso'] = 'unknown'\n",
    "df_ufo_clean.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the cleaned data (final version)\n",
    "df_ufo_clean.to_csv('filename')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
